{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "deep_learning_lab.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "plgsDXm9AcK7",
        "colab_type": "text"
      },
      "source": [
        "# Deep Learning Lab\n",
        "Stephen Casper, scasper@college.harvard.edu"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BFsw7RSo3Scb",
        "colab_type": "text"
      },
      "source": [
        "### Imports and Google Drive Filesystem Configuration\n",
        "Also, make sure to connect to a GPU runtime. Above, select Runtime > Change runtime type > Hardware accelerator > GPU."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2thRm2cvoCAm",
        "colab_type": "code",
        "outputId": "8b616c3b-2b30-4928-bcbf-ddfbd98e5a4c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        }
      },
      "source": [
        "# Numpy is great for working with arrays and algebra.\n",
        "import numpy as np\n",
        "\n",
        "# SKLearn is useful for machine learning.\n",
        "import sklearn as skl\n",
        "\n",
        "# Pandas is helpful for working with tables of data.\n",
        "import pandas as pd\n",
        "\n",
        "# PyTorch is a state of the art deep learning library.\n",
        "import torch\n",
        "import torch.utils.data  # datasets\n",
        "import torchvision.datasets as dsets  # datasets\n",
        "import torchvision.transforms as transforms  # data transformations\n",
        "import torchvision  # for working with images \n",
        "import torch.nn as nn  # networks\n",
        "import torch.nn.functional as F  # key functions\n",
        "import torch.optim as optim  # optimizers\n",
        "\n",
        "# Matplotlib is great for plotting\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# For reproducibility\n",
        "np.random.seed(0)\n",
        "torch.manual_seed(0)\n",
        "\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U1-GHBAO7VkG",
        "colab_type": "text"
      },
      "source": [
        "### Train and Test Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pt1dgFyh7bP7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Function to train a network\n",
        "def train(model, train_loader, epochs, device):\n",
        "\n",
        "    print('Training...')\n",
        "\n",
        "    model.train()  # Put model in training mode\n",
        "\n",
        "    # Loss function and optimizer\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
        "\n",
        "    train_accs = []  # Initialize list for epoch accuracies.\n",
        "\n",
        "    # Iterate over epochs/passes of the training set.\n",
        "    for epoch in range(epochs):\n",
        "        print('Training epoch ' + str(epoch+1) + '...')\n",
        "\n",
        "        # To keep track of accuracy \n",
        "        epoch_total = 0\n",
        "        epoch_correct = 0\n",
        "\n",
        "        # Iterate over dataset\n",
        "        for X, y in train_loader:\n",
        "            X = X.to(device) # Pass X, y to the GPU. X may be augmented depending on the train loader. \n",
        "            y = y.to(device)\n",
        "            optimizer.zero_grad()  # Reset the gradeints.\n",
        "            y_hat = model(X)  # Get the outputs of the model.\n",
        "            loss = criterion(y_hat, y)  # Get the loss according to the criterion.\n",
        "            loss.backward()  # Backpropagate to calculate the gradients.\n",
        "            optimizer.step()  # Take an optimization step and adjust the model parameters.\n",
        "\n",
        "            _, pred_labels = torch.max(y_hat.data, 1)  # Get labels from the outputs.\n",
        "            epoch_total += y.size(0)  # Add to total.\n",
        "            epoch_correct += (pred_labels == y).sum()  # Add to correct.\n",
        "        \n",
        "        train_accs.append(float(int(epoch_correct)/epoch_total))  # Update list of epoch accuracies.\n",
        "\n",
        "    return train_accs\n",
        "\n",
        "# Function to test a network\n",
        "def test(model, test_loader, device):\n",
        "\n",
        "    print('Testing...')\n",
        "\n",
        "    model.eval()  # Put model in testing mode.\n",
        "\n",
        "    # To keep track of accuracy \n",
        "    test_total = 0\n",
        "    test_correct = 0\n",
        "\n",
        "    # Iterate over dataset\n",
        "    for X, y in test_loader:\n",
        "        X = X.to(device) # Pass X, y to the GPU.\n",
        "        y = y.to(device)\n",
        "        y_hat = model(X)  # Get the outputs of the model.\n",
        "        _, pred_labels = torch.max(y_hat.data, 1)  # Get labels from the outputs.\n",
        "        test_total += y.size(0)  # Add to total.\n",
        "        test_correct += (pred_labels == y).sum()  # Add to correct.\n",
        "        \n",
        "    return float(int(test_correct)/test_total)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dsY_n5E95O-_",
        "colab_type": "text"
      },
      "source": [
        "### Multilayer Perceptron for [Wisconsin Breast Cancer](https://www.kaggle.com/uciml/breast-cancer-wisconsin-data/kernels) Dataset\n",
        "You will need to make a Kaggle account, download the data, and upload it to google drive with the menu on the left. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1jEFOIQVpi55",
        "colab_type": "code",
        "outputId": "be4cfe99-f65a-4e53-90e7-fcf5572decc2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 311
        }
      },
      "source": [
        "# Get raw Wisconsin Breast Cancer data as pandas dataframe, extract labels, and drop useless columns.\n",
        "raw_df = pd.read_csv('/content/data.csv', delimiter=\",\")  # TODO CASPER CHANGE\n",
        "raw_shuffled_df = raw_df.sample(frac=1, random_state=0)  # Shuffle rows.\n",
        "labels_df = raw_shuffled_df['diagnosis']  # Get labels. They are 'M' for malignent and 'B' for benign.\n",
        "raw_shuffled_df = raw_shuffled_df.drop(columns=['id', 'diagnosis', 'Unnamed: 32'])  # drop columns we don't want in X.\n",
        "\n",
        "# Get data in np.array form.\n",
        "X = raw_shuffled_df.to_numpy()\n",
        "y = np.zeros(X.shape[0])\n",
        "y[labels_df == 'M'] = 1  # 0s and 1s\n",
        "\n",
        "# Split train and test data.\n",
        "n_total = X.shape[0]\n",
        "dims = X.shape[1]\n",
        "n_train = int(n_total * 0.5)\n",
        "X_train = X[:n_train]\n",
        "y_train = y[:n_train]\n",
        "X_test = X[n_train:]\n",
        "y_test = y[n_train:]\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "clf = RandomForestClassifier(max_depth=4, random_state=0)\n",
        "clf.fit(X_train, y_train)\n",
        "yclf_hat = clf.predict(X_test)\n",
        "print(np.sum(yclf_hat==y_test) / n_train)\n",
        "\n",
        "# Dataset class\n",
        "class basic_dataset(torch.utils.data.Dataset):  # This is a subclass of torch.utils.data.Dataset.\n",
        "\n",
        "    def __init__(self, X, y):  # Initialization function\n",
        "\n",
        "        # Standardize and get from numpy.\n",
        "        self.X = torch.from_numpy((X - np.mean(X, axis=0)) / np.std(X, axis=0)).float()\n",
        "        self.y = torch.from_numpy(y).long()\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.X.size(0)  # Return length.\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.X[idx], self.y[idx]  # Return item.\n",
        "\n",
        "# Neural Network\n",
        "class WBC_MLP(nn.Module):  # This is a subclass of torch.nn.Module.\n",
        "\n",
        "    def __init__(self):  # Initialization function\n",
        "        super(WBC_MLP, self).__init__()  # Initialization function for parent class.\n",
        "\n",
        "        # Instantiate l2 hidden layers.\n",
        "        self.linear1 = nn.Linear(dims, 10)\n",
        "        self.linear2 = nn.Linear(10, 2)\n",
        "\n",
        "    def forward(self, X):  # Function to get network's output.\n",
        "\n",
        "        X = F.relu(self.linear1(X))\n",
        "        X = self.linear2(X)\n",
        "        return X\n",
        "\n",
        "# Use GPU.\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'  # use GPU if possible\n",
        "\n",
        "# Get model.\n",
        "wbc_model = WBC_MLP().to(device)\n",
        "\n",
        "# Get data loaders.\n",
        "wbc_train_loader = torch.utils.data.DataLoader(dataset=basic_dataset(X_train, y_train), batch_size=8, shuffle=True)\n",
        "wbc_test_loader = torch.utils.data.DataLoader(dataset=basic_dataset(X_test, y_test), batch_size=8)\n",
        "\n",
        "# Train and test.\n",
        "wbc_train_accs = train(model=wbc_model, train_loader=wbc_train_loader, epochs=10, device=device)\n",
        "wbc_test_acc = test(model=wbc_model, test_loader=wbc_test_loader, device=device)\n",
        "\n",
        "# Report results.\n",
        "print('Random guess baseline:', 1-np.mean(y))\n",
        "print('Train accuracies:', wbc_train_accs)\n",
        "print('Test accuracy:', wbc_test_acc)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9471830985915493\n",
            "Training...\n",
            "Training epoch 1...\n",
            "Training epoch 2...\n",
            "Training epoch 3...\n",
            "Training epoch 4...\n",
            "Training epoch 5...\n",
            "Training epoch 6...\n",
            "Training epoch 7...\n",
            "Training epoch 8...\n",
            "Training epoch 9...\n",
            "Training epoch 10...\n",
            "Testing...\n",
            "Random guess baseline: 0.6274165202108963\n",
            "Train accuracies: [0.795774647887324, 0.9366197183098591, 0.9647887323943662, 0.9823943661971831, 0.9859154929577465, 0.9894366197183099, 0.9894366197183099, 0.9929577464788732, 0.9894366197183099, 0.9894366197183099]\n",
            "Test accuracy: 0.9578947368421052\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OdeOTGSt5aQ4",
        "colab_type": "text"
      },
      "source": [
        "### Convolutional Neural Network for [CIFAR-10](https://www.cs.toronto.edu/~kriz/cifar.html)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G6FgKxcD5emG",
        "colab_type": "code",
        "outputId": "b6231c92-173a-4b12-cb39-a85fa506afd5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        }
      },
      "source": [
        "# Set up transformations\n",
        "train_transform_cifar10 = transforms.Compose([transforms.RandomCrop(32, padding=4),  # Random crop\n",
        "                                      transforms.RandomHorizontalFlip(p=0.5), # Random flip\n",
        "                                      transforms.ToTensor(), \n",
        "                                      transforms.Normalize((0, 0, 0), (1, 1, 1))])  # Normalize\n",
        "test_transform_cifar10 = transforms.Compose([transforms.ToTensor(), \n",
        "                                      transforms.Normalize((0, 0, 0), (1, 1, 1))])  # Normalize\n",
        "\n",
        "# Get CIFAR-10 data. PyTorch already has this one available.\n",
        "trainset_cifar10 = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=train_transform_cifar10)  # 50000 images\n",
        "testset_cifar10 = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=test_transform_cifar10)  # 10000 images\n",
        "\n",
        "# Standard convolutional net with 2 conv/pooling layers and 3 fc layers\n",
        "class CIFAR10_CNN(nn.Module):  \n",
        "    \n",
        "    def __init__(self, p=0.2):\n",
        "        super(CIFAR10_CNN, self).__init__()  # Initialize parent class\n",
        "\n",
        "        self.conv1 = nn.Conv2d(3, 8, 4)  # First convolution\n",
        "        self.conv2 = nn.Conv2d(8, 16, 4)  # Second convolution\n",
        "        self.pool = nn.MaxPool2d(2, 2)  # Max pooling \n",
        "        self.fc1 = nn.Linear(400, 200)  # Fully connected 1\n",
        "        self.fc2 = nn.Linear(200, 100)  # Fully connected 2\n",
        "        self.fc3 = nn.Linear(100, 10)  # Fully connected 2\n",
        "        self.drop = nn.Dropout(p=p)  # Dropout for fully connected layers\n",
        "\n",
        "    def forward(self, X):  # Function to get network's output.\n",
        "        X = self.pool(F.relu(self.conv1(X)))\n",
        "        X = self.pool(F.relu(self.conv2(X)))\n",
        "        X = X.view(-1, 400)\n",
        "        X = F.relu(self.drop(self.fc1(X)))\n",
        "        X = F.relu(self.drop(self.fc2(X)))\n",
        "        X = self.fc3(X)\n",
        "        return X\n",
        "\n",
        "# Use GPU.\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'  # use GPU if possible\n",
        "\n",
        "# Get model.\n",
        "cifar10_model = CIFAR10_CNN().to(device)\n",
        "\n",
        "# Get data loaders.\n",
        "cifar10_train_loader = torch.utils.data.DataLoader(trainset_cifar10, batch_size=32, shuffle=True)\n",
        "cifar10_test_loader = torch.utils.data.DataLoader(testset_cifar10, batch_size=32, shuffle=False)\n",
        "\n",
        "# Train and test.\n",
        "cifar10_train_accs = train(model=cifar10_model, train_loader=cifar10_train_loader, epochs=10, device=device)\n",
        "cifar10_test_acc = test(model=cifar10_model, test_loader=cifar10_test_loader, device=device)\n",
        "\n",
        "# Report results.\n",
        "print('random guess baseline:', 0.1)\n",
        "print('train accuracies:', cifar10_train_accs)\n",
        "print('test accuracy:', cifar10_test_acc)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 0/170498071 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "170500096it [00:01, 90254472.20it/s]                               \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n",
            "Training...\n",
            "Training epoch 1...\n",
            "Training epoch 2...\n",
            "Training epoch 3...\n",
            "Training epoch 4...\n",
            "Training epoch 5...\n",
            "Training epoch 6...\n",
            "Training epoch 7...\n",
            "Training epoch 8...\n",
            "Training epoch 9...\n",
            "Training epoch 10...\n",
            "Testing...\n",
            "random guess baseline: 0.1\n",
            "train accuracies: [0.24242, 0.37892, 0.42652, 0.44852, 0.4675, 0.48124, 0.49542, 0.49958, 0.5057, 0.51322]\n",
            "test accuracy: 0.5701\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "54QyrGiDdv3Z",
        "colab_type": "text"
      },
      "source": [
        "### Activity: Implement Something!\n",
        "\n",
        "- Preprocess Winsconsin data with [PCA](https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html) or [t-SNE](https://scikit-learn.org/stable/modules/generated/sklearn.manifold.TSNE.html).\n",
        "- Use another algorithm with the Wisconsin data like a [linear](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html) or [random forest](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html) classifier.\n",
        "- Experiment with batch size and learning rate in the CIFAR-10 network.\n",
        "- Experiment with the size and depth of layers in the CIFAR-10 network. Also consider adding residual (skip) connections. \n",
        "- Experiment with another [activation function](https://pytorch.org/docs/stable/nn.functional.html) (other than ReLU) and another [optimizer](https://pytorch.org/docs/stable/optim.html) other than SGD with the CIFAR-10 network.\n",
        "- Implement [batch normalization](https://discuss.pytorch.org/t/batch-normalization-of-linear-layers/20989) with the CIFAR-10 network. \n"
      ]
    }
  ]
}